import timeimport csvimport osfrom fairpyx.allocations import AllocationBuilderfrom fairpyx.algorithms.leximin_primal_before import leximin_primal as leximin_primal_beforefrom fairpyx.algorithms.leximin_primal_after import leximin_primal as leximin_primal_afterfrom cvxpy_leximin import Problem as LexiProblem, Leximin as LexiObjectiveimport cvxpyimport pandas as pdimport matplotlib.pyplot as pltimport randomclass CustomInstance:    """    A lightweight instance representation used for fair allocation experiments.    """    def __init__(self, valuations, agent_capacities, item_capacities):        self.valuations = valuations        self.agent_capacities = agent_capacities        self.item_capacities = item_capacities        self.agents = list(valuations.keys())        self.items = sorted({item for prefs in valuations.values() for item in prefs})    def agent_item_value(self, agent, item):        return self.valuations.get(agent, {}).get(item, 0)def evaluate_allocation(distribution, instance):    """    Given a randomized allocation, compute:    - the minimum utility among all agents    - the total sum of utilities    """    agent_values = {i: 0 for i in instance.agents}    for bundle, prob in distribution:        for agent, items in bundle.items():            agent_values[agent] += prob * sum(                instance.agent_item_value(agent, item) * qty                for item, qty in items.items()            )    values = list(agent_values.values())    return min(values), sum(values)def run_fairpyx_before(instance):    """    Run the original LeximinPrimal (before optimization) on a Fairpyx instance.    """    from fairpyx.instances import Instance as FairpyxInstance    fairpyx_inst = FairpyxInstance(        valuations=instance.valuations,        agent_capacities=instance.agent_capacities,        item_capacities=instance.item_capacities    )    alloc = AllocationBuilder(fairpyx_inst)    start = time.time()    leximin_primal_before(alloc)    runtime = time.time() - start    min_u, sum_u = evaluate_allocation(alloc.distribution, instance)    return runtime, min_u, sum_udef run_fairpyx_after(instance):    """    Run the optimized LeximinPrimal algorithm (after applying speedups).    """    from fairpyx.instances import Instance as FairpyxInstance    fairpyx_inst = FairpyxInstance(        valuations=instance.valuations,        agent_capacities=instance.agent_capacities,        item_capacities=instance.item_capacities    )    alloc = AllocationBuilder(fairpyx_inst)    start = time.time()    leximin_primal_after(alloc)    runtime = time.time() - start    min_u, sum_u = evaluate_allocation(alloc.distribution, instance)    return runtime, min_u, sum_udef convert_instance_to_cvxpy_problem(instance):    """    Convert a fair allocation instance into a CVXPY problem with Leximin objective.    """    agents = instance.agents    items = instance.items    n, m = len(agents), len(items)    agent_map = {agent: i for i, agent in enumerate(agents)}    item_map = {item: j for j, item in enumerate(items)}    a = cvxpy.Variable((n, m), nonneg=True)  # Allocation matrix    constraints = []    # Agent capacity constraints    for agent in agents:        i = agent_map[agent]        constraints.append(cvxpy.sum(a[i, :]) <= instance.agent_capacities[agent])    # Item capacity constraints    for item in items:        j = item_map[item]        constraints.append(cvxpy.sum(a[:, j]) <= instance.item_capacities[item])    # No more than 1 unit of any item per agent    for i in range(n):        for j in range(m):            constraints.append(a[i, j] <= 1)    # Utility expressions per agent    utilities = []    for agent in agents:        i = agent_map[agent]        u = sum(            instance.agent_item_value(agent, item) * a[i, item_map[item]]            for item in items        )        utilities.append(u)    return a, utilities, constraintsdef run_cvxpy(instance):    """    Solve the Leximin problem using CVXPY as an external benchmark.    """    a, utilities, constraints = convert_instance_to_cvxpy_problem(instance)    objective = LexiObjective(utilities)    problem = LexiProblem(objective, constraints)    start = time.time()    problem.solve()    runtime = time.time() - start    return runtime, min(objective.value), sum(objective.value)def generate_random_instance(n, m):    """    Generate a random instance with:    - each agent choosing 1â€“2 random items    - Fi valuations = {0,1}    - agent capacity = 1    - item capacities = random between 1 and 2    """    agents = list(range(1, n + 1))    items = [f"i{j}" for j in range(1, m + 1)]    valuations = {}    agent_capacities = {}    item_capacities = {}    for agent in agents:        preferred_items = random.sample(items, k=min(2, m))        valuations[agent] = {item: 1 for item in preferred_items}        agent_capacities[agent] = 1    for item in items:        item_capacities[item] = random.randint(1, 2)    return CustomInstance(valuations, agent_capacities, item_capacities)def run_random_experiments():    """    Run experiments comparing the 3 algorithms on inputs of increasing size.    Saves results as CSV and prints summary.    """    os.makedirs("experiments-csv", exist_ok=True)    with open("experiments-csv/random_inputs.csv", "w", newline="") as f:        writer = csv.writer(f)        writer.writerow(["n", "m", "algorithm", "runtime", "min_utility", "sum_utility"])        sizes = [3, 5, 7, 8, 9, 10, 11, 12]        max_runtime = 30  # stop testing if any algorithm takes too long        for size in sizes:            n = m = size            print(f"\nRunning experiments for n={n}, m={m}")            instance = generate_random_instance(n, m)            exceeded_runtime = False            for algo_name, runner in [                ("leximin_primal_before", run_fairpyx_before),                ("leximin_primal_after", run_fairpyx_after),                ("cvxpy_leximin", run_cvxpy)            ]:                try:                    runtime, min_u, sum_u = runner(instance)                    writer.writerow([n, m, algo_name, runtime, min_u, sum_u])                    print(f"{algo_name}: {runtime:.4f}s, min={min_u:.2f}, sum={sum_u:.2f}")                    if runtime > max_runtime:                        print(f"Max runtime reached for {algo_name} at n={n}, m={m}")                        exceeded_runtime = True                except Exception as e:                    print(f"{algo_name} failed at n={n}, m={m}: {e}")            if exceeded_runtime:                print("Stopping further sizes due to max runtime.")                breakdef plot_results():    csv_path = "experiments-csv/random_inputs.csv"    if not os.path.exists(csv_path):        print("CSV file not found, skipping plot.")        return    df = pd.read_csv(csv_path)    plt.figure(figsize=(10, 6))    for algo in df["algorithm"].unique():        data = df[df["algorithm"] == algo]        plt.plot(data["n"], data["runtime"], label=algo)    plt.xlabel("Number of agents/items (n = m)")    plt.ylabel("Runtime (seconds)")    plt.title("Runtime vs Input Size")    plt.legend()    plt.grid(True)    plt.tight_layout()    plt.savefig("experiments-csv/runtime_comparison.png")    plt.show()if __name__ == "__main__":    os.makedirs("experiments-csv", exist_ok=True)    # Run the experiments and write the CSV    run_random_experiments()    # Now generate the plot AFTER the CSV is written    plot_results()